# Case TÃ©cnico de Engenharia de Dados - Letrus

## ğŸ¯ Objetivo

Centralizar dados acadÃªmicos em uma arquitetura simples e eficiente: um Ãºnico ETL unificado (AWS Glue) que lÃª os arquivos fonte, gera uma tabela desnormalizada e persiste o resultado no S3 (Parquet) e no Amazon Aurora (PostgreSQL).

---

## ğŸ—ï¸ Diagrama da Arquitetura (simplificada)

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CSV Local  â”‚â”€â”€â–¶ â”‚ S3 (raw)     â”‚â”€â”€â–¶ â”‚ Glue Job Ãºnico:          â”‚â”€â”€â–¶ â”‚ S3 (processed)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ etl_performance_academicaâ”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚                         
                                         â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚ Aurora (RDS) â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Outros componentes:
- CloudWatch Logs: logs do Glue Job.
- Secrets Manager: credenciais do Aurora.
```

---

## ğŸ“‚ Estrutura de Arquivos
letrus-data-case/ 
â”œâ”€â”€ terraform/ 
â”‚ â”œâ”€â”€ modules/ 
â”‚ â”‚ â”œâ”€â”€ 1_networking/ 
â”‚ â”‚ â”œâ”€â”€ 2_iam/ 
â”‚ â”‚ â”œâ”€â”€ 3_s3/ 
â”‚ â”‚ â”œâ”€â”€ 4_rds_aurora/ 
â”‚ â”‚ â””â”€â”€ 5_glue/ 
â”‚ â”œâ”€â”€ main.tf 
â”‚ â”œâ”€â”€ variables.tf 
â”‚ â”œâ”€â”€ outputs.tf 
â”‚ â””â”€â”€ terraform.tfvars 
â”œâ”€â”€ glue_scripts/ 
â”‚ â”œâ”€â”€ etl_performance_academica.py 
â”‚ â””â”€â”€ common.py
â”œâ”€â”€ sql/ 
â”‚ â”œâ”€â”€ 01_create_tables.sql 
â”‚ â””â”€â”€ 02_analysis_queries.sql 
â”œâ”€â”€ csv_exemplos/ 
â”‚ â”œâ”€â”€ alunos.csv 
â”‚ â”œâ”€â”€ escolas.csv 
â”‚ â””â”€â”€ notas.csv 
â””â”€â”€ README.md

---

## ğŸ› ï¸ Tecnologias Utilizadas

* **Infraestrutura como CÃ³digo:** Terraform
* **Armazenamento:** Amazon S3, Amazon Aurora (PostgreSQL)
* **ETL e OrquestraÃ§Ã£o:** AWS Glue (um Ãºnico Job)
* **SeguranÃ§a:** AWS IAM, AWS Secrets Manager
* **Monitoramento:** AWS CloudWatch
* **Linguagens:** Python (PySpark), SQL

---

## ğŸš€ Passo a Passo da ExecuÃ§Ã£o

### 1. PrÃ©-requisitos

* Conta AWS configurada com credenciais (AWS CLI).
* Terraform instalado.
* Um cliente SQL (DBeaver, DataGrip, psql) para conectar ao Aurora.

#### Backend remoto (S3) â€” criaÃ§Ã£o do bucket

O backend do Terraform neste projeto estÃ¡ configurado para armazenar o state em um bucket S3. O arquivo `terraform/backend.tf` referencia o bucket atual:

```
bucket = "letrus-de-case-terraform-state"
key    = "global/terraform.tfstate"
region = "us-east-1"
```

Esse bucket precisa existir antes de executar `terraform init`. Abaixo hÃ¡ comandos AWS CLI (PowerShell) para criar o bucket, habilitar criptografia padrÃ£o.

ObservaÃ§Ãµes rÃ¡pidas:
- Substitua `letrus-de-case-terraform-state` por um nome globalmente Ãºnico se necessÃ¡rio.

Exemplos (sh / AWS CLI):

```sh
# 1) Criar bucket em us-east-1
aws s3api create-bucket --bucket letrus-de-case-terraform-state --region us-east-1

# 2) Habilitar criptografia padrÃ£o (server-side encryption AES256)
aws s3api put-bucket-encryption --bucket letrus-de-case-terraform-state --server-side-encryption-configuration '{"Rules":[{"ApplyServerSideEncryptionByDefault":{"SSEAlgorithm":"AES256"}}]}'
```

Depois de criar o bucket continue os passos. 

### 2. Deploy da Infraestrutura (Terraform)

1. Clone este repositÃ³rio.
2. Preencha as variÃ¡veis (ex: `project_name` e `region`).
3. Navegue atÃ© o diretÃ³rio `terraform/` e execute:

    ```powershell
    terraform init
    terraform plan
    terraform apply -auto-approve
    ```

4. Aguarde o provisionamento (VPC, S3, Aurora e Glue).
5. **Anote os outputs importantes** exibidos pelo Terraform:
    * `bucket_data_name` â€” nome do bucket S3.
    * `aurora_cluster_endpoint` â€” host do banco.
    * `secret_manager_aurora_credentials_arn` â€” ARN do secret com credenciais do DB.
    * `glue_job_performance_academica_name` â€” nome do Glue Job Ãºnico.

### 3. ExecuÃ§Ã£o do Pipeline (Glue Job Ãºnico)

1. **Preparar o Banco de Dados (Primeira vez):**
    - No AWS Secrets Manager, obtenha o secret (`secret_manager_aurora_credentials_arn`).
    - Conecte-se ao Aurora e execute `sql/01_create_tables.sql` para criar a tabela desnormalizada `performance_academica`.

2. **Executar o Glue Job:**
    - No console AWS Glue (ou via API), execute o job `${project_name}-etl-performance-academica`.
    - O job lÃª os CSVs de `raw/` (`alunos.csv`, `escolas.csv`, `notas.csv`), gera a tabela desnormalizada, grava Parquet em `processed/performance_academica/<run>` e faz upsert no Aurora.
    - O upsert usa chave composta `(aluno_id, escola_id, disciplina)` para permitir mÃºltiplas linhas por aluno/disciplinas.

### 4. Consultas no Aurora

* Execute as queries em `sql/02_analysis_queries.sql` para anÃ¡lises sobre `performance_academica`.
